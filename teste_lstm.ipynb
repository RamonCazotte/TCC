{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa0_xh9oUdRj"
      },
      "source": [
        "# Modelo de deep learning baseado na memória de curto prazo (LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0jRdlNqUdRs"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "# Install missing packages\n",
        "%pip install pandas_datareader\n",
        "\n",
        "from pandas_datareader import data as pdr\n",
        "\n",
        "#pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "-1aG6D2jUdRu",
        "outputId": "9d18b1c1-bdaa-40d0-c035-4a2b6f264962"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade pandas_datareader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdr.get_data_yahoo('PETR4.SA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "acao = \"PETR4.SA\"\n",
        "\n",
        "inicio = \"2014-12-31\"\n",
        "final = \"2022-09-15\"\n",
        "\n",
        "try:\n",
        "\tdados_acao = pdr.get_data_yahoo(acao, inicio, final)\n",
        "\tprint(dados_acao)\n",
        "except Exception as e:\n",
        "\tprint(f\"Error fetching data: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VmnT252UdRu"
      },
      "outputs": [],
      "source": [
        "#nao pode ser ajustados\n",
        "\n",
        "#obtem a cotação de fechamento em um array\n",
        "cotacao = dados_acao['Close'].to_numpy().reshape(-1, 1)\n",
        "\n",
        "cotacao"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anYmyuOMUdRu"
      },
      "outputs": [],
      "source": [
        "#separa a base de treino com 80% dos dados. Poderia ter utlizado o train_test_split do sklearn e a literatura recomenda 70/30\n",
        "tamanho_dados_treinamento = int(len(cotacao) * 0.8)\n",
        "\n",
        "#imprime a quantidade de dados do vetor de treinamento\n",
        "tamanho_dados_treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOcZf0oXUdRv",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#escalar os dados entre 0 e 1, para deixar mais fácil o processamento\n",
        "#dados em escala pré definidas são mais fáceis de lidar.\n",
        "\n",
        "escalador = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "dados_entre_0_e_1_treinamento = escalador.fit_transform(cotacao[0: tamanho_dados_treinamento, :])\n",
        "\n",
        "dados_entre_0_e_1_teste = escalador.transform(cotacao[tamanho_dados_treinamento: , :])\n",
        "\n",
        "dados_entre_0_e_1 = list(dados_entre_0_e_1_treinamento.reshape(\n",
        "    len(dados_entre_0_e_1_treinamento))) + list(dados_entre_0_e_1_teste.reshape(len(dados_entre_0_e_1_teste)))\n",
        "\n",
        "\n",
        "dados_entre_0_e_1 = np.array(dados_entre_0_e_1).reshape(len(dados_entre_0_e_1), 1)\n",
        "\n",
        "dados_entre_0_e_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIQQcHwSUdRv"
      },
      "outputs": [],
      "source": [
        "dados_para_treinamento = dados_entre_0_e_1[0: tamanho_dados_treinamento, :]\n",
        "\n",
        "#dados que serão usados para gerar o resultado\n",
        "treinamento_x = []\n",
        "#cotação que aconteceu de fato\n",
        "treinamento_y = []\n",
        "\n",
        "#IMPORTANTE\n",
        "#O modelo é treinado baseado nos últimos 60 dias para prever o próximo dia, sempre seguindo esse clico\n",
        "#Ou seja, do 0 ao 59 para prever o 60, do 1 ao 60 para prever o 61, do 2 ao 61 para prever o 62 e assim por diante\n",
        "\n",
        "for i in range(60, len(dados_para_treinamento)):\n",
        "\n",
        "    #60 ultimos dias\n",
        "    treinamento_x.append(dados_para_treinamento[i - 60: i, 0])\n",
        "    #cotacao\n",
        "    treinamento_y.append(dados_para_treinamento[i, 0])\n",
        "\n",
        "    if i <= 61:\n",
        "\n",
        "        print(treinamento_x)\n",
        "        print(treinamento_y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VL0V6W9nUdRw"
      },
      "outputs": [],
      "source": [
        "#transformando as listas em arrays e dando reshape 3d\n",
        "\n",
        "treinamento_x, treinamento_y = np.array(treinamento_x), np.array(treinamento_y)\n",
        "\n",
        "print(treinamento_x)\n",
        "\n",
        "treinamento_x = treinamento_x.reshape(treinamento_x.shape[0], treinamento_x.shape[1], 1)\n",
        "\n",
        "print(treinamento_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlOGQgFGUdRw"
      },
      "outputs": [],
      "source": [
        "#construindo o modelo\n",
        "\n",
        "modelo = Sequential()\n",
        "\n",
        "#vamos criar um modelo com 50 neurônios\n",
        "#return sequences = True pois vamos usar outro LSTM depois.\n",
        "#definir o shape, que no caso são 60 informações para gerar uma.\n",
        "#Adicionar mais neurônios com o dense, 25 e 1\n",
        "#Não se apegue a isso agora, é apenas um arquitetura de deep learning.\n",
        "\n",
        "modelo.add(LSTM(50, return_sequences=True, input_shape = (treinamento_x.shape[1], 1)))\n",
        "modelo.add(LSTM(50, return_sequences=False))\n",
        "modelo.add(Dense(25))\n",
        "modelo.add(Dense(1))\n",
        "\n",
        "treinamento_x.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDiSI1dRUdRw"
      },
      "outputs": [],
      "source": [
        "#copilando o modelo\n",
        "\n",
        "# a função de loss é a forma de medir o erro do modelo, que nesse caso\n",
        "#é o classico erro médio quadrático da que é usado em regressão linear\n",
        "#otimizador e medida de erro\n",
        "\n",
        "modelo.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eNq9yBAUdRx"
      },
      "outputs": [],
      "source": [
        "#agora com o modelo copilado e os dados, podemos treinar o modelo\n",
        "#batch size é depois de quantas em quantas amostras o modelo irá otimizar os parâmetros.\n",
        "#epochs é quantas vezes o algoritmo irá rodar os dados treinamento, aprendendo.\n",
        "\n",
        "modelo.fit(treinamento_x, treinamento_y, batch_size=1, epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AozmVg2UdRx"
      },
      "outputs": [],
      "source": [
        "#criar dados de teste\n",
        "\n",
        "dados_teste = dados_entre_0_e_1[tamanho_dados_treinamento - 60:, :]\n",
        "\n",
        "teste_x = []\n",
        "teste_y = cotacao[tamanho_dados_treinamento: , :]\n",
        "\n",
        "for i in range(60, len(dados_teste)):\n",
        "    teste_x.append(dados_teste[i - 60: i, 0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBcZ5rxIUdRx"
      },
      "outputs": [],
      "source": [
        "#reshape\n",
        "teste_x = np.array(teste_x)\n",
        "teste_x = teste_x.reshape(teste_x.shape[0], teste_x.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hVJBKSrUdRx"
      },
      "outputs": [],
      "source": [
        "#pegando predições do modelo\n",
        "\n",
        "predicoes = modelo.predict(teste_x)\n",
        "\n",
        "#tirando a escala dos dados\n",
        "\n",
        "predicoes = escalador.inverse_transform(predicoes)\n",
        "\n",
        "predicoes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng7Rg6XHUdRx"
      },
      "outputs": [],
      "source": [
        "#pegando o erro médio quadrático (RMSE)\n",
        "\n",
        "rmse = np.sqrt(np.mean(predicoes - teste_y) ** 2)\n",
        "rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gh0QpYAMUdRx"
      },
      "outputs": [],
      "source": [
        "#criando o grafico do modelo\n",
        "\n",
        "\n",
        "treinamento = dados_acao.iloc[:tamanho_dados_treinamento, :]\n",
        "df_teste = pd.DataFrame({\"Close\": dados_acao['Close'].iloc[tamanho_dados_treinamento:],\n",
        "                        \"predicoes\": predicoes.reshape(len(predicoes))})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urr5bJu0UdRx"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize =(16, 8))\n",
        "plt.title('Modelo')\n",
        "plt.xlabel('Data', fontsize = 18)\n",
        "plt.ylabel(\"Preço de fechamento\", fontsize = 18)\n",
        "plt.plot(treinamento['Close'])\n",
        "plt.plot(df_teste[['Close', 'predicoes']])\n",
        "plt.legend(['Treinamento', 'Real', 'Predições'], loc=2, prop={'size': 16})\n",
        "plt.show()\n",
        "\n",
        "#essa queda pegou o modelo despevinido, pois MGLU só subia até então praticamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHoRlntWUdRx"
      },
      "outputs": [],
      "source": [
        "df_teste.sort_index()\n",
        "\n",
        "df_teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsuwK5IrUdRy"
      },
      "outputs": [],
      "source": [
        "#o preço é legal, mas o importante é acertar pra qual mercado o lado vai. Sera q isso foi feito?\n",
        "\n",
        "#calcular media de acertos e expectativa de lucro\n",
        "\n",
        "df_teste['variacao_percentual_acao'] = df_teste['Close'].pct_change()\n",
        "df_teste['variacao_percentual_modelo'] = df_teste['predicoes'].pct_change()\n",
        "\n",
        "df_teste = df_teste.dropna()\n",
        "\n",
        "df_teste['var_acao_maior_menor_que_zero'] = np.where(df_teste['variacao_percentual_acao'] > 0,\n",
        "                                                      True, False)\n",
        "df_teste['var_modelo_maior_menor_que_zero'] = np.where(df_teste['variacao_percentual_modelo'] > 0,\n",
        "                                                      True, False)\n",
        "\n",
        "df_teste['acertou_o_lado'] = np.where(df_teste['var_acao_maior_menor_que_zero'] == df_teste['var_modelo_maior_menor_que_zero']\n",
        "                                      , True, False)\n",
        "\n",
        "df_teste['variacao_percentual_acao_abs'] = df_teste['variacao_percentual_acao'].abs()\n",
        "\n",
        "df_teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGQK7wYGUdRy"
      },
      "outputs": [],
      "source": [
        "acertou_lado = df_teste['acertou_o_lado'].sum()/len(df_teste['acertou_o_lado'])\n",
        "errou_lado = 1 - acertou_lado\n",
        "\n",
        "media_lucro = df_teste.groupby('acertou_o_lado')['variacao_percentual_acao_abs'].mean()\n",
        "\n",
        "exp_mat_lucro = acertou_lado * media_lucro[1] - media_lucro[0] * errou_lado\n",
        "\n",
        "ganho_sobre_perda = media_lucro[1]/media_lucro[0]\n",
        "\n",
        "print(media_lucro)\n",
        "print(ganho_sobre_perda)\n",
        "print(acertou_lado)\n",
        "print(exp_mat_lucro * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyZ15OWqUdRy"
      },
      "outputs": [],
      "source": [
        "#criando um código que você passa 60 dias e ele devolve a cotação\n",
        "#resumindo: vamos descobrir o preço da petrobras de hoje/amanha com esse modelo\n",
        "\n",
        "data_hoje = datetime.now()\n",
        "\n",
        "#se quiser escolher um dia, basta fazer assim\n",
        "\n",
        "#data_hoje = datetime.now() - timedelta(days = 1)\n",
        "\n",
        "if data_hoje.hour > 18:\n",
        "\n",
        "    final = data_hoje\n",
        "    inicial = datetime.now() - timedelta(days = 252)\n",
        "\n",
        "else:\n",
        "    final = data_hoje - timedelta(days = 1)\n",
        "    inicial = datetime.now() - timedelta(days = 252)\n",
        "\n",
        "#nao vai botar outra ação aqui hein kkkkkkkk\n",
        "cotacoes = pdr.get_data_yahoo(acao, inicial, final)\n",
        "ultimos_60_dias = cotacoes['Close'].iloc[-60:].values.reshape(-1, 1)\n",
        "\n",
        "ultimos_60_dias_escalado = escalador.transform(ultimos_60_dias)\n",
        "\n",
        "teste_x = []\n",
        "teste_x.append(ultimos_60_dias_escalado)\n",
        "teste_x = np.array(teste_x)\n",
        "teste_x = teste_x.reshape(teste_x.shape[0], teste_x.shape[1], 1)\n",
        "\n",
        "previsao_de_preco = modelo.predict(teste_x)\n",
        "previsao_de_preco = escalador.inverse_transform(previsao_de_preco)\n",
        "\n",
        "print(previsao_de_preco)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZigHaTIUdRy"
      },
      "source": [
        "# Sugestões:\n",
        "<br>\n",
        "\n",
        "- Melhorar as estatísticas de avaliação (dias seguidos ganhando, max DD, etc)\n",
        "<br>\n",
        "\n",
        "- Rodar pra todas as ações do ibovespa e criar uma expectativa matemática da expectativa matemática. Isso vai deixar o resultado final ainda mais robusto, definando a aloção do $ basedo na liquidez\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wq_Bb6AgUdRy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
