{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa0_xh9oUdRj"
      },
      "source": [
        "# Modelo de deep learning baseado na memória de curto prazo (LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f0jRdlNqUdRs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas_datareader in c:\\python312\\lib\\site-packages (0.10.0)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: lxml in c:\\python312\\lib\\site-packages (from pandas_datareader) (5.3.0)\n",
            "Requirement already satisfied: pandas>=0.23 in c:\\python312\\lib\\site-packages (from pandas_datareader) (2.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\python312\\lib\\site-packages (from pandas_datareader) (2.31.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\python312\\lib\\site-packages (from pandas>=0.23->pandas_datareader) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python312\\lib\\site-packages (from pandas>=0.23->pandas_datareader) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas>=0.23->pandas_datareader) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas>=0.23->pandas_datareader) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.23->pandas_datareader) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "# Install missing packages\n",
        "%pip install pandas_datareader\n",
        "\n",
        "import yfinance as yf\n",
        "\n",
        "#pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "-1aG6D2jUdRu",
        "outputId": "9d18b1c1-bdaa-40d0-c035-4a2b6f264962"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas_datareader in c:\\python312\\lib\\site-packages (0.10.0)\n",
            "Requirement already satisfied: lxml in c:\\python312\\lib\\site-packages (from pandas_datareader) (5.3.0)\n",
            "Requirement already satisfied: pandas>=0.23 in c:\\python312\\lib\\site-packages (from pandas_datareader) (2.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\python312\\lib\\site-packages (from pandas_datareader) (2.31.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\python312\\lib\\site-packages (from pandas>=0.23->pandas_datareader) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python312\\lib\\site-packages (from pandas>=0.23->pandas_datareader) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas>=0.23->pandas_datareader) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas>=0.23->pandas_datareader) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests>=2.19.0->pandas_datareader) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.23->pandas_datareader) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade pandas_datareader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Price       Adj Close      Close       High        Low       Open    Volume\n",
            "Ticker       PETR4.SA   PETR4.SA   PETR4.SA   PETR4.SA   PETR4.SA  PETR4.SA\n",
            "Date                                                                       \n",
            "2020-01-16   9.468792  29.520000  29.700001  29.330000  29.600000  28997400\n",
            "2020-01-17   9.574640  29.850000  29.850000  29.540001  29.719999  34908000\n",
            "2020-01-20   9.622755  30.000000  30.100000  29.650000  29.700001  31241400\n",
            "2020-01-21   9.500866  29.620001  29.940001  29.549999  29.799999  28577400\n",
            "2020-01-22   9.395015  29.290001  29.809999  29.270000  29.730000  32491500\n",
            "...               ...        ...        ...        ...        ...       ...\n",
            "2025-01-09  36.840000  36.840000  36.970001  36.700001  36.700001  11526600\n",
            "2025-01-10  36.939999  36.939999  37.520000  36.900002  37.250000  40328800\n",
            "2025-01-13  37.070000  37.070000  37.529999  36.970001  37.299999  22897100\n",
            "2025-01-14  36.820000  36.820000  37.130001  36.580002  37.110001  29173100\n",
            "2025-01-15  37.290001  37.290001  37.320000  36.799999  36.930000  32512700\n",
            "\n",
            "[1244 rows x 6 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "acao = \"PETR4.SA\"\n",
        "\n",
        "inicio = \"2020-01-16\"\n",
        "final = \"2025-01-16\"\n",
        "\n",
        "dados_acao = yf.download(acao, inicio, final)\n",
        "print(dados_acao)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8VmnT252UdRu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[29.52000046],\n",
              "       [29.85000038],\n",
              "       [30.        ],\n",
              "       ...,\n",
              "       [37.06999969],\n",
              "       [36.81999969],\n",
              "       [37.29000092]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#nao pode ser ajustados\n",
        "\n",
        "#obtem a cotação de fechamento em um array\n",
        "cotacao = dados_acao['Close'].to_numpy().reshape(-1, 1)\n",
        "\n",
        "cotacao"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "anYmyuOMUdRu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "995"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#separa a base de treino com 80% dos dados. Poderia ter utlizado o train_test_split do sklearn e a literatura recomenda 70/30\n",
        "tamanho_dados_treinamento = int(len(cotacao) * 0.8)\n",
        "\n",
        "#imprime a quantidade de dados do vetor de treinamento\n",
        "tamanho_dados_treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "hOcZf0oXUdRv",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.65883632],\n",
              "       [0.6707626 ],\n",
              "       [0.67618362],\n",
              "       ...,\n",
              "       [0.931695  ],\n",
              "       [0.92265994],\n",
              "       [0.93964589]])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#escalar os dados entre 0 e 1, para deixar mais fácil o processamento\n",
        "#dados em escala pré definidas são mais fáceis de lidar.\n",
        "\n",
        "escalador = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "dados_entre_0_e_1_treinamento = escalador.fit_transform(cotacao[0: tamanho_dados_treinamento, :])\n",
        "\n",
        "dados_entre_0_e_1_teste = escalador.transform(cotacao[tamanho_dados_treinamento: , :])\n",
        "\n",
        "dados_entre_0_e_1 = list(dados_entre_0_e_1_treinamento.reshape(\n",
        "    len(dados_entre_0_e_1_treinamento))) + list(dados_entre_0_e_1_teste.reshape(len(dados_entre_0_e_1_teste)))\n",
        "\n",
        "\n",
        "dados_entre_0_e_1 = np.array(dados_entre_0_e_1).reshape(len(dados_entre_0_e_1), 1)\n",
        "\n",
        "dados_entre_0_e_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "TIQQcHwSUdRv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([0.65883632, 0.6707626 , 0.67618362, 0.66245036, 0.65052409,\n",
            "       0.66353452, 0.65088543, 0.6049874 , 0.63281532, 0.63462237,\n",
            "       0.637875  , 0.62016629, 0.61040842, 0.62667148, 0.61799783,\n",
            "       0.64654864, 0.63751359, 0.64474159, 0.65739068, 0.68088181,\n",
            "       0.66606433, 0.65522229, 0.65305389, 0.66714856, 0.69606071,\n",
            "       0.6732924 , 0.645103  , 0.53921213, 0.50632453, 0.50777017,\n",
            "       0.55077706, 0.5334297 , 0.56378749, 0.50596319, 0.4170582 ,\n",
            "       0.17202745, 0.22659919, 0.16479944, 0.04734371, 0.14853631,\n",
            "       0.06505241, 0.06179979, 0.        , 0.03324901, 0.02565956,\n",
            "       0.00758945, 0.07083484, 0.10950487, 0.11203471, 0.07264186,\n",
            "       0.07553308, 0.0975786 , 0.10878209, 0.15251176, 0.14636792,\n",
            "       0.16190823, 0.18467654, 0.21792555, 0.19985544, 0.20383088])]\n",
            "[0.1966028100064599]\n",
            "[array([0.65883632, 0.6707626 , 0.67618362, 0.66245036, 0.65052409,\n",
            "       0.66353452, 0.65088543, 0.6049874 , 0.63281532, 0.63462237,\n",
            "       0.637875  , 0.62016629, 0.61040842, 0.62667148, 0.61799783,\n",
            "       0.64654864, 0.63751359, 0.64474159, 0.65739068, 0.68088181,\n",
            "       0.66606433, 0.65522229, 0.65305389, 0.66714856, 0.69606071,\n",
            "       0.6732924 , 0.645103  , 0.53921213, 0.50632453, 0.50777017,\n",
            "       0.55077706, 0.5334297 , 0.56378749, 0.50596319, 0.4170582 ,\n",
            "       0.17202745, 0.22659919, 0.16479944, 0.04734371, 0.14853631,\n",
            "       0.06505241, 0.06179979, 0.        , 0.03324901, 0.02565956,\n",
            "       0.00758945, 0.07083484, 0.10950487, 0.11203471, 0.07264186,\n",
            "       0.07553308, 0.0975786 , 0.10878209, 0.15251176, 0.14636792,\n",
            "       0.16190823, 0.18467654, 0.21792555, 0.19985544, 0.20383088]), array([0.6707626 , 0.67618362, 0.66245036, 0.65052409, 0.66353452,\n",
            "       0.65088543, 0.6049874 , 0.63281532, 0.63462237, 0.637875  ,\n",
            "       0.62016629, 0.61040842, 0.62667148, 0.61799783, 0.64654864,\n",
            "       0.63751359, 0.64474159, 0.65739068, 0.68088181, 0.66606433,\n",
            "       0.65522229, 0.65305389, 0.66714856, 0.69606071, 0.6732924 ,\n",
            "       0.645103  , 0.53921213, 0.50632453, 0.50777017, 0.55077706,\n",
            "       0.5334297 , 0.56378749, 0.50596319, 0.4170582 , 0.17202745,\n",
            "       0.22659919, 0.16479944, 0.04734371, 0.14853631, 0.06505241,\n",
            "       0.06179979, 0.        , 0.03324901, 0.02565956, 0.00758945,\n",
            "       0.07083484, 0.10950487, 0.11203471, 0.07264186, 0.07553308,\n",
            "       0.0975786 , 0.10878209, 0.15251176, 0.14636792, 0.16190823,\n",
            "       0.18467654, 0.21792555, 0.19985544, 0.20383088, 0.19660281])]\n",
            "[0.1966028100064599, 0.18395371739468575]\n"
          ]
        }
      ],
      "source": [
        "dados_para_treinamento = dados_entre_0_e_1[0: tamanho_dados_treinamento, :]\n",
        "\n",
        "#dados que serão usados para gerar o resultado\n",
        "treinamento_x = []\n",
        "#cotação que aconteceu de fato\n",
        "treinamento_y = []\n",
        "\n",
        "#IMPORTANTE\n",
        "#O modelo é treinado baseado nos últimos 60 dias para prever o próximo dia, sempre seguindo esse clico\n",
        "#Ou seja, do 0 ao 59 para prever o 60, do 1 ao 60 para prever o 61, do 2 ao 61 para prever o 62 e assim por diante\n",
        "\n",
        "for i in range(60, len(dados_para_treinamento)):\n",
        "\n",
        "    #60 ultimos dias\n",
        "    treinamento_x.append(dados_para_treinamento[i - 60: i, 0])\n",
        "    #cotacao\n",
        "    treinamento_y.append(dados_para_treinamento[i, 0])\n",
        "\n",
        "    if i <= 61:\n",
        "\n",
        "        print(treinamento_x)\n",
        "        print(treinamento_y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "VL0V6W9nUdRw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.65883632 0.6707626  0.67618362 ... 0.21792555 0.19985544 0.20383088]\n",
            " [0.6707626  0.67618362 0.66245036 ... 0.19985544 0.20383088 0.19660281]\n",
            " [0.67618362 0.66245036 0.65052409 ... 0.20383088 0.19660281 0.18395372]\n",
            " ...\n",
            " [0.91760033 0.95337908 0.98409835 ... 0.95627036 0.96783522 0.97144919]\n",
            " [0.95337908 0.98409835 0.9775931  ... 0.96783522 0.97144919 0.98626681]\n",
            " [0.98409835 0.9775931  0.95988433 ... 0.97144919 0.98626681 0.96891938]]\n",
            "[[[0.65883632]\n",
            "  [0.6707626 ]\n",
            "  [0.67618362]\n",
            "  ...\n",
            "  [0.21792555]\n",
            "  [0.19985544]\n",
            "  [0.20383088]]\n",
            "\n",
            " [[0.6707626 ]\n",
            "  [0.67618362]\n",
            "  [0.66245036]\n",
            "  ...\n",
            "  [0.19985544]\n",
            "  [0.20383088]\n",
            "  [0.19660281]]\n",
            "\n",
            " [[0.67618362]\n",
            "  [0.66245036]\n",
            "  [0.65052409]\n",
            "  ...\n",
            "  [0.20383088]\n",
            "  [0.19660281]\n",
            "  [0.18395372]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.91760033]\n",
            "  [0.95337908]\n",
            "  [0.98409835]\n",
            "  ...\n",
            "  [0.95627036]\n",
            "  [0.96783522]\n",
            "  [0.97144919]]\n",
            "\n",
            " [[0.95337908]\n",
            "  [0.98409835]\n",
            "  [0.9775931 ]\n",
            "  ...\n",
            "  [0.96783522]\n",
            "  [0.97144919]\n",
            "  [0.98626681]]\n",
            "\n",
            " [[0.98409835]\n",
            "  [0.9775931 ]\n",
            "  [0.95988433]\n",
            "  ...\n",
            "  [0.97144919]\n",
            "  [0.98626681]\n",
            "  [0.96891938]]]\n"
          ]
        }
      ],
      "source": [
        "#transformando as listas em arrays e dando reshape 3d\n",
        "\n",
        "treinamento_x, treinamento_y = np.array(treinamento_x), np.array(treinamento_y)\n",
        "\n",
        "print(treinamento_x)\n",
        "\n",
        "treinamento_x = treinamento_x.reshape(treinamento_x.shape[0], treinamento_x.shape[1], 1)\n",
        "\n",
        "print(treinamento_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "AlOGQgFGUdRw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#construindo o modelo\n",
        "\n",
        "modelo = Sequential()\n",
        "\n",
        "#vamos criar um modelo com 50 neurônios\n",
        "#return sequences = True pois vamos usar outro LSTM depois.\n",
        "#definir o shape, que no caso são 60 informações para gerar uma.\n",
        "#Adicionar mais neurônios com o dense, 25 e 1\n",
        "#Não se apegue a isso agora, é apenas um arquitetura de deep learning.\n",
        "\n",
        "modelo.add(LSTM(50, return_sequences=True, input_shape = (treinamento_x.shape[1], 1)))\n",
        "modelo.add(LSTM(50, return_sequences=False))\n",
        "modelo.add(Dense(25))\n",
        "modelo.add(Dense(1))\n",
        "\n",
        "treinamento_x.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "WDiSI1dRUdRw"
      },
      "outputs": [],
      "source": [
        "#copilando o modelo\n",
        "\n",
        "# a função de loss é a forma de medir o erro do modelo, que nesse caso\n",
        "#é o classico erro médio quadrático da que é usado em regressão linear\n",
        "#otimizador e medida de erro\n",
        "\n",
        "modelo.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4eNq9yBAUdRx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m935/935\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 28ms/step - loss: 0.0191\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x2610a4af650>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#agora com o modelo copilado e os dados, podemos treinar o modelo\n",
        "#batch size é depois de quantas em quantas amostras o modelo irá otimizar os parâmetros.\n",
        "#epochs é quantas vezes o algoritmo irá rodar os dados treinamento, aprendendo.\n",
        "\n",
        "modelo.fit(treinamento_x, treinamento_y, batch_size=1, epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2AozmVg2UdRx"
      },
      "outputs": [],
      "source": [
        "#criar dados de teste\n",
        "\n",
        "dados_teste = dados_entre_0_e_1[tamanho_dados_treinamento - 60:, :]\n",
        "\n",
        "teste_x = []\n",
        "teste_y = cotacao[tamanho_dados_treinamento: , :]\n",
        "\n",
        "for i in range(60, len(dados_teste)):\n",
        "    teste_x.append(dados_teste[i - 60: i, 0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "uBcZ5rxIUdRx"
      },
      "outputs": [],
      "source": [
        "#reshape\n",
        "teste_x = np.array(teste_x)\n",
        "teste_x = teste_x.reshape(teste_x.shape[0], teste_x.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "4hVJBKSrUdRx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "249"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#pegando predições do modelo\n",
        "\n",
        "predicoes = modelo.predict(teste_x)\n",
        "\n",
        "#tirando a escala dos dados\n",
        "\n",
        "predicoes = escalador.inverse_transform(predicoes)\n",
        "\n",
        "len(predicoes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ng7Rg6XHUdRx"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "249"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#pegando o erro médio quadrático (RMSE)\n",
        "\n",
        "rmse = np.sqrt(np.mean(predicoes - teste_y) ** 2)\n",
        "rmse\n",
        "len(predicoes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "995"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tamanho_dados_treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "gh0QpYAMUdRx"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th>Price</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Close</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ticker</th>\n",
              "      <th>PETR4.SA</th>\n",
              "      <th>PETR4.SA</th>\n",
              "      <th>PETR4.SA</th>\n",
              "      <th>PETR4.SA</th>\n",
              "      <th>PETR4.SA</th>\n",
              "      <th>PETR4.SA</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-01-16</th>\n",
              "      <td>9.468792</td>\n",
              "      <td>29.520000</td>\n",
              "      <td>29.700001</td>\n",
              "      <td>29.330000</td>\n",
              "      <td>29.600000</td>\n",
              "      <td>28997400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-17</th>\n",
              "      <td>9.574640</td>\n",
              "      <td>29.850000</td>\n",
              "      <td>29.850000</td>\n",
              "      <td>29.540001</td>\n",
              "      <td>29.719999</td>\n",
              "      <td>34908000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-20</th>\n",
              "      <td>9.622755</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>30.100000</td>\n",
              "      <td>29.650000</td>\n",
              "      <td>29.700001</td>\n",
              "      <td>31241400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-21</th>\n",
              "      <td>9.500866</td>\n",
              "      <td>29.620001</td>\n",
              "      <td>29.940001</td>\n",
              "      <td>29.549999</td>\n",
              "      <td>29.799999</td>\n",
              "      <td>28577400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-22</th>\n",
              "      <td>9.395015</td>\n",
              "      <td>29.290001</td>\n",
              "      <td>29.809999</td>\n",
              "      <td>29.270000</td>\n",
              "      <td>29.730000</td>\n",
              "      <td>32491500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-11</th>\n",
              "      <td>31.092249</td>\n",
              "      <td>38.070000</td>\n",
              "      <td>38.150002</td>\n",
              "      <td>37.700001</td>\n",
              "      <td>37.980000</td>\n",
              "      <td>26564400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-12</th>\n",
              "      <td>31.173916</td>\n",
              "      <td>38.169998</td>\n",
              "      <td>38.730000</td>\n",
              "      <td>38.169998</td>\n",
              "      <td>38.500000</td>\n",
              "      <td>24479500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-15</th>\n",
              "      <td>31.508774</td>\n",
              "      <td>38.580002</td>\n",
              "      <td>38.619999</td>\n",
              "      <td>37.860001</td>\n",
              "      <td>37.990002</td>\n",
              "      <td>13818300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-16</th>\n",
              "      <td>31.116751</td>\n",
              "      <td>38.099998</td>\n",
              "      <td>38.790001</td>\n",
              "      <td>38.080002</td>\n",
              "      <td>38.610001</td>\n",
              "      <td>31277700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-17</th>\n",
              "      <td>30.937069</td>\n",
              "      <td>37.880001</td>\n",
              "      <td>38.150002</td>\n",
              "      <td>37.820000</td>\n",
              "      <td>37.970001</td>\n",
              "      <td>27577300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>995 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "Price       Adj Close      Close       High        Low       Open    Volume\n",
              "Ticker       PETR4.SA   PETR4.SA   PETR4.SA   PETR4.SA   PETR4.SA  PETR4.SA\n",
              "Date                                                                       \n",
              "2020-01-16   9.468792  29.520000  29.700001  29.330000  29.600000  28997400\n",
              "2020-01-17   9.574640  29.850000  29.850000  29.540001  29.719999  34908000\n",
              "2020-01-20   9.622755  30.000000  30.100000  29.650000  29.700001  31241400\n",
              "2020-01-21   9.500866  29.620001  29.940001  29.549999  29.799999  28577400\n",
              "2020-01-22   9.395015  29.290001  29.809999  29.270000  29.730000  32491500\n",
              "...               ...        ...        ...        ...        ...       ...\n",
              "2024-01-11  31.092249  38.070000  38.150002  37.700001  37.980000  26564400\n",
              "2024-01-12  31.173916  38.169998  38.730000  38.169998  38.500000  24479500\n",
              "2024-01-15  31.508774  38.580002  38.619999  37.860001  37.990002  13818300\n",
              "2024-01-16  31.116751  38.099998  38.790001  38.080002  38.610001  31277700\n",
              "2024-01-17  30.937069  37.880001  38.150002  37.820000  37.970001  27577300\n",
              "\n",
              "[995 rows x 6 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#criando o grafico do modelo\n",
        "treinamento = dados_acao.iloc[:tamanho_dados_treinamento, :]\n",
        "treinamento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Data must be 1-dimensional, got ndarray of shape (249, 1) instead",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_teste \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mClose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdados_acao\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mClose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtamanho_dados_treinamento\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredicoes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicoes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpredicoes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:767\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    761\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    762\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    763\u001b[0m     )\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 767\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:119\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     arrays, refs \u001b[38;5;241m=\u001b[39m \u001b[43m_homogenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# _homogenize ensures\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    125\u001b[0m \n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:629\u001b[0m, in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    626\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(val)\n\u001b[0;32m    627\u001b[0m     val \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mfast_multiget(val, oindex\u001b[38;5;241m.\u001b[39m_values, default\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m--> 629\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m com\u001b[38;5;241m.\u001b[39mrequire_length_match(val, index)\n\u001b[0;32m    631\u001b[0m refs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\construction.py:630\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# e.g. dask array GH#38645\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m--> 630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     _sanitize_non_ordered(data)\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\construction.py:656\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    653\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n\u001b[0;32m    654\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[1;32m--> 656\u001b[0m subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[0;32m    660\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mdtype, dtype)\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\construction.py:715\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[1;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allow_2d:\n\u001b[0;32m    714\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 715\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    716\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must be 1-dimensional, got ndarray of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    717\u001b[0m     )\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;66;03m# i.e. NumpyEADtype(\"O\")\u001b[39;00m\n\u001b[0;32m    721\u001b[0m     result \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
            "\u001b[1;31mValueError\u001b[0m: Data must be 1-dimensional, got ndarray of shape (249, 1) instead"
          ]
        }
      ],
      "source": [
        "df_teste = pd.DataFrame({\"Close\": dados_acao['Close'].iloc[tamanho_dados_treinamento:],\n",
        "                        \"predicoes\": predicoes.reshape(len(predicoes))})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Data must be 1-dimensional, got ndarray of shape (249, 1) instead",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_teste \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mClose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdados_acao\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mClose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtamanho_dados_treinamento\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredicoes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicoes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpredicoes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:767\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    761\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    762\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    763\u001b[0m     )\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 767\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:119\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     arrays, refs \u001b[38;5;241m=\u001b[39m \u001b[43m_homogenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# _homogenize ensures\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    125\u001b[0m \n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:629\u001b[0m, in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    626\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(val)\n\u001b[0;32m    627\u001b[0m     val \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mfast_multiget(val, oindex\u001b[38;5;241m.\u001b[39m_values, default\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m--> 629\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m com\u001b[38;5;241m.\u001b[39mrequire_length_match(val, index)\n\u001b[0;32m    631\u001b[0m refs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\construction.py:630\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# e.g. dask array GH#38645\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m--> 630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     _sanitize_non_ordered(data)\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\construction.py:656\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    653\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n\u001b[0;32m    654\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[1;32m--> 656\u001b[0m subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[0;32m    660\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mdtype, dtype)\n",
            "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\construction.py:715\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[1;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allow_2d:\n\u001b[0;32m    714\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 715\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    716\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must be 1-dimensional, got ndarray of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    717\u001b[0m     )\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;66;03m# i.e. NumpyEADtype(\"O\")\u001b[39;00m\n\u001b[0;32m    721\u001b[0m     result \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
            "\u001b[1;31mValueError\u001b[0m: Data must be 1-dimensional, got ndarray of shape (249, 1) instead"
          ]
        }
      ],
      "source": [
        "df_teste = pd.DataFrame({\"Close\": dados_acao['Close'].iloc[tamanho_dados_treinamento:],\n",
        "                        \"predicoes\": predicoes.reshape(len(predicoes))})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urr5bJu0UdRx"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize =(16, 8))\n",
        "plt.title('Modelo')\n",
        "plt.xlabel('Data', fontsize = 18)\n",
        "plt.ylabel(\"Preço de fechamento\", fontsize = 18)\n",
        "plt.plot(treinamento['Close'])\n",
        "plt.plot(df_teste[['Close', 'predicoes']])\n",
        "plt.legend(['Treinamento', 'Real', 'Predições'], loc=2, prop={'size': 16})\n",
        "plt.show()\n",
        "\n",
        "#essa queda pegou o modelo despevinido, pois MGLU só subia até então praticamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHoRlntWUdRx"
      },
      "outputs": [],
      "source": [
        "df_teste.sort_index()\n",
        "\n",
        "df_teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsuwK5IrUdRy"
      },
      "outputs": [],
      "source": [
        "#o preço é legal, mas o importante é acertar pra qual mercado o lado vai. Sera q isso foi feito?\n",
        "\n",
        "#calcular media de acertos e expectativa de lucro\n",
        "\n",
        "df_teste['variacao_percentual_acao'] = df_teste['Close'].pct_change()\n",
        "df_teste['variacao_percentual_modelo'] = df_teste['predicoes'].pct_change()\n",
        "\n",
        "df_teste = df_teste.dropna()\n",
        "\n",
        "df_teste['var_acao_maior_menor_que_zero'] = np.where(df_teste['variacao_percentual_acao'] > 0,\n",
        "                                                      True, False)\n",
        "df_teste['var_modelo_maior_menor_que_zero'] = np.where(df_teste['variacao_percentual_modelo'] > 0,\n",
        "                                                      True, False)\n",
        "\n",
        "df_teste['acertou_o_lado'] = np.where(df_teste['var_acao_maior_menor_que_zero'] == df_teste['var_modelo_maior_menor_que_zero']\n",
        "                                      , True, False)\n",
        "\n",
        "df_teste['variacao_percentual_acao_abs'] = df_teste['variacao_percentual_acao'].abs()\n",
        "\n",
        "df_teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGQK7wYGUdRy"
      },
      "outputs": [],
      "source": [
        "acertou_lado = df_teste['acertou_o_lado'].sum()/len(df_teste['acertou_o_lado'])\n",
        "errou_lado = 1 - acertou_lado\n",
        "\n",
        "media_lucro = df_teste.groupby('acertou_o_lado')['variacao_percentual_acao_abs'].mean()\n",
        "\n",
        "exp_mat_lucro = acertou_lado * media_lucro[1] - media_lucro[0] * errou_lado\n",
        "\n",
        "ganho_sobre_perda = media_lucro[1]/media_lucro[0]\n",
        "\n",
        "print(media_lucro)\n",
        "print(ganho_sobre_perda)\n",
        "print(acertou_lado)\n",
        "print(exp_mat_lucro * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyZ15OWqUdRy"
      },
      "outputs": [],
      "source": [
        "#criando um código que você passa 60 dias e ele devolve a cotação\n",
        "#resumindo: vamos descobrir o preço da petrobras de hoje/amanha com esse modelo\n",
        "\n",
        "data_hoje = datetime.now()\n",
        "\n",
        "#se quiser escolher um dia, basta fazer assim\n",
        "\n",
        "#data_hoje = datetime.now() - timedelta(days = 1)\n",
        "\n",
        "if data_hoje.hour > 18:\n",
        "\n",
        "    final = data_hoje\n",
        "    inicial = datetime.now() - timedelta(days = 252)\n",
        "\n",
        "else:\n",
        "    final = data_hoje - timedelta(days = 1)\n",
        "    inicial = datetime.now() - timedelta(days = 252)\n",
        "\n",
        "#nao vai botar outra ação aqui hein kkkkkkkk\n",
        "cotacoes = pdr.get_data_yahoo(acao, inicial, final)\n",
        "ultimos_60_dias = cotacoes['Close'].iloc[-60:].values.reshape(-1, 1)\n",
        "\n",
        "ultimos_60_dias_escalado = escalador.transform(ultimos_60_dias)\n",
        "\n",
        "teste_x = []\n",
        "teste_x.append(ultimos_60_dias_escalado)\n",
        "teste_x = np.array(teste_x)\n",
        "teste_x = teste_x.reshape(teste_x.shape[0], teste_x.shape[1], 1)\n",
        "\n",
        "previsao_de_preco = modelo.predict(teste_x)\n",
        "previsao_de_preco = escalador.inverse_transform(previsao_de_preco)\n",
        "\n",
        "print(previsao_de_preco)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZigHaTIUdRy"
      },
      "source": [
        "# Sugestões:\n",
        "<br>\n",
        "\n",
        "- Melhorar as estatísticas de avaliação (dias seguidos ganhando, max DD, etc)\n",
        "<br>\n",
        "\n",
        "- Rodar pra todas as ações do ibovespa e criar uma expectativa matemática da expectativa matemática. Isso vai deixar o resultado final ainda mais robusto, definando a aloção do $ basedo na liquidez\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wq_Bb6AgUdRy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
